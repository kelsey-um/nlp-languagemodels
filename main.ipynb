{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree as ET #lxml is faster\n",
    "import glob #to use multiple files\n",
    "from collections import Counter #to count unique words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count:  11616\n"
     ]
    }
   ],
   "source": [
    "#one file\n",
    "\n",
    "tree = ET.parse('dataset/A1E.xml')\n",
    "root = tree.getroot()\n",
    "# print(root)\n",
    "\n",
    "text=[]\n",
    "\n",
    "for s in root.iter('s'):\n",
    "    text.append('<s>')\n",
    "    for elem in s.findall('*'):\n",
    "        text.append(elem.text)\n",
    "    text.append('</s>')\n",
    "\n",
    "print(\"Word count: \",len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count:  5392173\n"
     ]
    }
   ],
   "source": [
    "#all files\n",
    "\n",
    "files = glob.glob('fulldataset/*.xml')\n",
    "\n",
    "textfull = []\n",
    "\n",
    "for fileName in files:\n",
    "    \n",
    "    tree = ET.parse(fileName)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for s in root.iter('s'):\n",
    "        textfull.append('<s>')\n",
    "        for elem in s.findall('*'):\n",
    "            textfull.append(elem.text)\n",
    "        textfull.append('</s>')\n",
    "    \n",
    "print(\"Word count: \",len(textfull))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unqiue words and their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = {}\n",
    "\n",
    "for word in text:\n",
    "    if word in uniqueWords:\n",
    "        uniqueWords[word] += 1\n",
    "    else:\n",
    "        uniqueWords[word] = 1\n",
    "\n",
    "# for word, count in uniqueWords.items():\n",
    "#     print(f\"{word}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(text, n): #n is size of ngrams\n",
    "\n",
    "    ngramCounts = {} #dict to store ngrams\n",
    "\n",
    "    for i in range(len(text)-n+1): #len(text)-n+1 is the number of all possible ngrams\n",
    "\n",
    "        ngram = tuple(text[i:i+n]) #creates ngram\n",
    "\n",
    "        if ngram in ngramCounts: #check to see if it already exists\n",
    "            ngramCounts[ngram] += 1\n",
    "        else:\n",
    "            ngramCounts[ngram] = 1\n",
    "\n",
    "    return ngramCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramCounter(text, n): #ngram function using counter\n",
    "    \n",
    "    ngramCounts = Counter()\n",
    "\n",
    "    for i in range(len(text)-n+1):\n",
    "        ngram = tuple(text[i:i+n])\n",
    "        ngramCounts[ngram] += 1\n",
    "    \n",
    "    return ngramCounts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing ngram function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststring = '<s> I am Sam </s> <s> Sam I am </s> <s> I do not like green eggs and ham </s>'\n",
    "testlist = list(teststring.split(\" \"))\n",
    "\n",
    "# print(\"Unigram:\\n\",ngram(testlist,1), \"\\n\")\n",
    "# print(\"Bigram:\\n\",ngram(testlist,2), \"\\n\")\n",
    "# print(\"Trigram:\\n\",ngram(testlist,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcNGramProbabilities(text, n):\n",
    "    ngrams = ngram(text, n)\n",
    "\n",
    "    totalNgrams = len(text) - n + 1\n",
    "    \n",
    "    ngramProbs = {ngram: count / totalNgrams for ngram, count in ngrams.items()}\n",
    "    \n",
    "    # ngramProbs = \n",
    "    \n",
    "    return ngramProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>', 'I'): 0.10526315789473684,\n",
       " ('I', 'am'): 0.10526315789473684,\n",
       " ('am', 'Sam'): 0.05263157894736842,\n",
       " ('Sam', '</s>'): 0.05263157894736842,\n",
       " ('</s>', '<s>'): 0.10526315789473684,\n",
       " ('<s>', 'Sam'): 0.05263157894736842,\n",
       " ('Sam', 'I'): 0.05263157894736842,\n",
       " ('am', '</s>'): 0.05263157894736842,\n",
       " ('I', 'do'): 0.05263157894736842,\n",
       " ('do', 'not'): 0.05263157894736842,\n",
       " ('not', 'like'): 0.05263157894736842,\n",
       " ('like', 'green'): 0.05263157894736842,\n",
       " ('green', 'eggs'): 0.05263157894736842,\n",
       " ('eggs', 'and'): 0.05263157894736842,\n",
       " ('and', 'ham'): 0.05263157894736842,\n",
       " ('ham', '</s>'): 0.05263157894736842}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcNGramProbabilities(testlist,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e556872412c9668e080d844f72a9aacd3b42500e70ed86345b6212c46b5b8406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
